//this file was auto-generated by convert_dnn_to_cpp.py
#ifndef H_RW_MMP
#define H_RW_MMP

#include <cmath>
#include <vector>

/*!\class rw_mmp
 class containing DNN such as one produced by TensorFlow
 */
class rw_mmp {
public:
  /*!\brief Standard constrctor for initializing DNN
   */
  rw_mmp();

  enum class ActivationType{relu, elu, sigmoid};

  /*!\brief evaluates DNN score at a point input
   */
  float evaluate(std::vector<float> input) const;

private:
  std::vector<float> scale(std::vector<float> input) const;
  float dot_product(std::vector<float> x, std::vector<float> y) const;
  float relu(float x) const;
  float elu(float x) const;
  float sigmoid(float x) const;

  unsigned n_layer;
  unsigned n_input;
  std::vector<float> scale_lamb;
  std::vector<float> scale_mean;
  std::vector<float> scale_stdv;
  std::vector<unsigned> n_unit;
  std::vector<rw_mmp::ActivationType> activation_type;
  std::vector<std::vector<std::vector<float>>> weight;
  std::vector<std::vector<float>> bias;
};

rw_mmp::rw_mmp() :
  n_layer(4),
  n_input(4),
  scale_lamb{},
  scale_mean{26.233800176877537,0.9126498134714879,0.8170650862103003,0.02351230706180137},
  scale_stdv{10.626761292376875,0.639180411601262,0.16389030244001063,0.013475013173904888},
  n_unit{15,15,15,1},
  activation_type{ActivationType::elu,ActivationType::elu,ActivationType::elu,ActivationType::sigmoid},
  weight{{{-0.20496039,-0.755371,1.3538876,0.026376477},{-0.010861519,0.23689617,-1.0357939,0.07553605},{-0.021597903,1.7943115,0.015343817,-0.03679847},{0.40357113,-1.0583804,-0.8594903,-2.2772944},{-1.0627222,-1.1918317,-1.2201848,0.6725638},{-1.0297804,-0.3948244,4.5750804,-0.5313525},{0.5799727,-0.4791096,3.2935085,-0.38605186},{-0.069024056,-0.61311746,-0.33112016,1.689687},{-0.17944992,-0.5945449,-0.1767843,-0.5408819},{-2.8758795,-0.04269421,-0.55602175,-0.32220528},{0.87973803,0.63332975,-0.46893224,-0.8310688},{-0.5653166,1.7714379,-0.42309177,-2.6742804},{1.3061929,-0.32550454,0.5527937,0.105196506},{0.036145575,1.865374,-0.1635321,0.34365538},{0.03616907,-0.6431795,3.3022957,0.64790505}},{{-0.9635431,1.4575157,0.837974,-1.7062477,2.1400948,0.8732286,1.6900826,-2.4202926,-0.07938878,-0.9375868,0.238276,-0.4064621,-0.9112877,1.42759,0.5843096},{-0.5989239,-0.77765304,2.851322,-0.6235984,0.31793797,1.6369172,-0.53152174,0.038573377,-0.9986946,-1.4887698,-3.6794508,1.5403912,-0.030133236,0.23672783,-0.030372916},{0.35380197,1.3915297,-1.3317473,1.7045213,-0.78912574,0.22819734,-0.05455137,1.1499544,-1.7765911,-1.6625688,0.55890375,1.5179168,-1.0055164,-2.778486,-0.0856505},{-0.18652794,-0.17723796,18.052422,1.7802877,0.081770055,-0.692245,0.4350907,-0.37884247,-0.14514558,0.2451066,-0.55359757,0.011021703,-0.38566437,1.7031072,-0.43235755},{-0.1816505,0.4551401,-0.009366103,0.79776335,0.4253393,0.2099287,-0.1272451,-2.3685825,-0.18524833,-1.1433963,-0.008476437,0.8989738,-0.8451516,-2.1245322,-1.0299879},{-0.8411614,-0.9489394,0.8434152,0.01741396,-1.0491107,-0.7217982,-0.9838502,0.21516776,-0.030682664,1.3381064,-1.0006864,1.2492598,1.0593231,1.4959835,-1.3593596},{0.27094844,-0.3658608,-2.9412014,1.0440649,1.314685,-3.00086,-0.8924377,-0.24692002,0.43088567,0.5310667,-1.1174638,-1.0163869,-1.7256261,0.12012337,-1.4597129},{-1.271748,-0.44248578,1.5510422,2.7374423,-0.5896937,0.49662915,-0.4609,-5.812264,-0.4523568,0.29187128,-1.4740045,-1.2563945,0.35571805,-0.15738277,0.19075632},{-0.018315356,-0.221423,-0.6731125,1.2538514,-0.03341226,1.0754735,-0.51837295,-1.0686828,-0.3312019,-0.46952713,-0.05088762,-2.4342377,0.017900478,-0.030804913,-1.5262536},{0.084162995,-0.26504093,-2.2911527,0.47633058,0.42298496,-1.666733,-0.1685926,-1.156259,-0.28450933,0.76378816,-0.4441269,1.185265,-0.6069197,0.5825344,-0.047998637},{1.5816418,0.54839224,1.640667,-0.1566773,-0.15598753,-1.556878,-2.6280792,-0.6470044,0.47712508,2.317305,-0.19561067,1.1730447,0.18620092,-0.21173471,0.6615858},{-1.3201079,0.84129417,-3.5089679,-0.5623339,0.09196284,-0.3048041,-0.18157122,-0.22976735,-1.1450372,-0.59479195,0.4354172,0.34264272,-0.35479188,0.93555844,0.8367023},{0.60712934,-0.35138226,0.02825484,0.6147384,0.26130593,0.6216724,-0.055575345,0.040769022,-1.0628539,-0.41965246,0.7306232,0.09695266,-0.7144628,1.4355129,0.05800091},{1.0562572,-2.440418,3.0328166,0.35868984,-0.82956094,-1.3711572,0.3881655,-1.1600752,-1.0664635,-1.0590994,-1.188926,0.48168322,-1.0224147,-0.6217445,0.97638863},{-0.70580906,2.3990304,0.91798496,-0.7473561,-3.1463478,1.2423279,1.6641091,-0.22894132,-1.6285597,-0.1669109,-3.2311606,-0.24975908,-0.35414296,0.21997607,1.9629022}},{{0.05434424,0.70783997,0.42213652,0.66055983,0.82523847,-0.5529968,0.078419656,-0.32937473,0.10005608,-0.83614576,-0.0068734535,-1.2284945,-2.2983727,-0.38334852,0.16969319},{0.00024223718,-0.04523471,-0.013718058,0.02575553,0.025702434,0.0056364364,0.019786788,-0.0013425464,-0.0037152153,-0.035913866,-0.027351243,-0.042545326,0.042283233,0.073881805,0.050316107},{0.48653314,0.49252015,-0.06533854,3.2996423,-0.05937641,0.15236406,-0.5038715,0.58435506,-0.15727076,-0.5753325,-0.057368085,0.61515856,0.32186908,0.2421806,-0.059685253},{0.26986238,0.96367025,-0.5931511,-0.5153865,-0.2139786,-1.1133844,-0.1841577,-1.9561766,0.8478269,0.041078396,0.4278762,0.57378405,-0.57756275,2.3545103,1.4589666},{0.017372018,-0.008650983,0.002716001,-0.008110838,0.0035425615,-0.0013111274,-0.003354282,0.02299375,-0.0069851587,0.00053505605,-0.0010377677,0.022397848,-0.030492136,0.007818849,-0.0294761},{-0.008386638,-0.029732578,0.0074210726,0.0051750243,0.009133596,-0.006467599,0.008783652,-0.01326784,0.009236989,-0.0149357775,-0.011697162,-0.021369405,0.018401107,0.056073334,0.033568256},{0.023632728,-0.05533752,-0.006071511,-0.038537145,0.030542228,0.039649263,0.003015767,-0.023348456,-0.0010180757,-0.023076478,-0.026744194,-0.012706034,-0.029470297,0.009293823,0.03901608},{-0.5683658,-1.2104348,-0.6883591,4.51235,0.0077087623,-0.2336784,-1.3960508,0.2556724,-0.0008441351,-0.5378098,-0.7797714,0.3745384,0.37313452,-0.29539543,0.53118104},{-0.14043333,0.12970777,0.40904063,-0.47239766,0.23467733,-0.0012116747,-0.2214027,-0.32002607,-0.17009567,-0.74330604,-0.9164408,0.33900136,0.5542815,-0.0063895313,-1.2215021},{-0.076574296,-0.019164074,-0.6559555,-0.31924874,0.12720314,-1.2096105,0.0018070437,0.40130863,-0.08755942,0.5312155,0.3505741,-0.37346113,0.8693798,0.29543716,0.0015168919},{-0.027008621,1.152859,-2.6517117,-2.2989607,0.34385958,-0.51902837,-0.08608343,1.0685478,-0.007564217,-0.22667459,0.46076185,-0.17680709,0.6499934,-0.52322143,2.2904968},{1.1219003,0.09104316,-0.09370141,-0.54840636,-0.8908159,0.045764375,-0.022772716,-0.012183929,0.75862026,-0.01756621,-0.4560666,0.12918216,-0.571647,-0.14237191,-0.26847413},{-1.4860021,-1.6262803,-0.26827165,1.0558177,1.8807015,0.7351083,-0.68958575,0.91294175,-1.4035444,-1.2555453,0.44655332,0.6436456,-0.1547811,-1.3597542,0.721137},{-0.6321758,0.7497167,-0.25847062,-1.0008961,-0.14127284,0.16612141,0.0682715,-2.7359858,-0.17431371,-0.016984945,-0.2832464,0.8916416,-0.41750836,0.8276012,0.10192941},{-0.019122517,0.023817133,-0.0037853972,0.025789155,0.0020493784,0.005436404,-0.0035269589,0.009693449,-0.0034438563,-0.002730079,-0.010002997,0.016585466,-0.011472836,-0.0016561208,-0.047389124}},{{0.086413875,0.0012732274,-0.107207574,-0.042445056,9.765058e-05,0.0011647317,0.0025495375,-0.22774827,0.045884833,0.061056394,0.07677189,0.048399113,-0.1333919,0.07786673,-0.00033589726}}},
  bias{{0.98020613,-1.7814898,-4.3373914,-0.6892426,-1.1863235,-2.2702265,-2.7403803,-0.039231192,2.0396776,-2.4321992,0.42785013,-2.6466968,-0.43859056,-3.595244,-1.3237008},{-0.17875238,-1.1089985,-0.8315471,-2.067913,-1.1360921,0.40267506,1.7389311,-2.692825,0.045581754,2.2290506,-0.6711071,-3.082586,0.9182266,-0.8504206,-2.7742925},{-1.5600688,0.02170537,-0.8942281,0.0037037442,0.016524663,-0.01308844,-0.012329335,-0.27803332,-1.6382784,-1.3786585,-1.8123792,-1.33255,-2.0116382,-1.7116189,0.04108161},{-0.4214863}} {}

float rw_mmp::evaluate(std::vector<float> input) const {
  std::vector<float> layer_input = scale(input);
  for (unsigned ilayer = 0; ilayer < n_layer; ilayer++) {
    std::vector<float> layer_output;
    layer_output.resize(n_unit[ilayer]);
    for (unsigned iunit = 0; iunit < n_unit[ilayer]; iunit++) {
      float unit_input = dot_product(layer_input,weight[ilayer][iunit])+bias[ilayer][iunit];
      if (activation_type[ilayer]==rw_mmp::ActivationType::relu)
        layer_output[iunit] = relu(unit_input);
      else if (activation_type[ilayer]==rw_mmp::ActivationType::sigmoid)
        layer_output[iunit] = sigmoid(unit_input);
      else if (activation_type[ilayer]==rw_mmp::ActivationType::elu)
        layer_output[iunit] = elu(unit_input);
    }
    layer_input = layer_output;
  }
  return layer_input[0];
}

float rw_mmp::relu(float x) const {
  if (x < 0) return 0;
  return x;
}

float rw_mmp::elu(float x) const {
  if (x < 0) return (exp(x)-1.0);
  return x;
}

float rw_mmp::sigmoid(float x) const {
  return 1.0/(1.0+exp(-1.0*x));
}

float rw_mmp::dot_product(std::vector<float> x, std::vector<float> y) const {
  float output = 0;
  for (unsigned i = 0; i < x.size(); i++) {
    output += x[i]*y[i];
  }
  return output;
}

std::vector<float> rw_mmp::scale(std::vector<float> input) const {
  std::vector<float> output;
  output.resize(n_input);
  for (unsigned iin = 0; iin < n_input; iin++) {
    output[iin] = (input[iin]-scale_mean[iin])/scale_stdv[iin];
  }
  return output;
}

#endif
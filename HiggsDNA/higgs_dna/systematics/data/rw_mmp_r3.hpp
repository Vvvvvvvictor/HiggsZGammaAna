//this file was auto-generated by convert_dnn_to_cpp.py
#ifndef H_RW_MMP_R3
#define H_RW_MMP_R3

#include <cmath>
#include <vector>

/*!\class rw_mmp_r3
 class containing DNN such as one produced by TensorFlow
 */
class rw_mmp_r3 {
public:
  /*!\brief Standard constrctor for initializing DNN
   */
  rw_mmp_r3();

  enum class ActivationType{relu, elu, sigmoid};

  /*!\brief evaluates DNN score at a point input
   */
  float evaluate(std::vector<float> input) const;

private:
  std::vector<float> scale(std::vector<float> input) const;
  float dot_product(std::vector<float> x, std::vector<float> y) const;
  float relu(float x) const;
  float elu(float x) const;
  float sigmoid(float x) const;

  unsigned n_layer;
  unsigned n_input;
  std::vector<float> scale_lamb;
  std::vector<float> scale_mean;
  std::vector<float> scale_stdv;
  std::vector<unsigned> n_unit;
  std::vector<rw_mmp_r3::ActivationType> activation_type;
  std::vector<std::vector<std::vector<float>>> weight;
  std::vector<std::vector<float>> bias;
};

rw_mmp_r3::rw_mmp_r3() :
  n_layer(4),
  n_input(4),
  scale_lamb{},
  scale_mean{23.286472651538666,0.9167020848261785,0.7698651115431332,0.022492932037320355},
  scale_stdv{8.53861583892226,0.6467834859505386,0.15903096690222765,0.016823906687277103},
  n_unit{15,15,15,1},
  activation_type{ActivationType::elu,ActivationType::elu,ActivationType::elu,ActivationType::sigmoid},
  weight{{{0.026357269,0.6192911,0.44189367,-1.6057551},{-3.7517006,-0.9631858,0.17823915,-0.19367142},{-0.078843616,-0.7665219,0.68823564,0.73007524},{-0.030608831,2.7837842,0.3124592,0.056952428},{0.18854375,1.9731625,-0.044632606,0.95765543},{0.017539121,0.015118076,-0.64912176,-10.375001},{-0.47689325,-1.0045582,-0.3289422,0.6714755},{0.81896615,-0.98661435,0.22965167,0.07258209},{0.20769313,-0.5525739,2.4933956,0.27861446},{-2.2300322,0.073239535,0.05626986,-1.152431},{0.974007,-1.4418147,1.402362,-2.9632933},{0.6271228,-0.8069959,-0.58514714,0.8066445},{0.6173461,-0.3629741,-1.383196,-2.871908},{1.1591694,0.189468,0.019780038,0.038948942},{-0.050273757,1.713172,-0.7568774,-0.3223946}},{{0.110258214,0.022999141,0.48164546,0.5765392,0.41198874,-0.47623768,0.3667311,0.7954784,-0.046161104,0.45987627,-0.5815145,-0.07487781,2.2122629,-1.2063777,0.13944207},{-0.15809953,-0.9035623,-0.53900254,1.4646107,-3.5537083,-1.6544793,-0.47429362,-1.321221,0.15450475,-0.37240463,0.35327265,-0.6453778,-0.15501675,0.8227643,-1.937151},{-1.8247949,-1.953178,-0.9944776,-0.03737882,-0.67647415,-0.39867625,-1.1803952,-0.99192184,0.50789446,-5.399393,1.3115621,-1.6391313,1.5797248,-3.0158522,-0.3167969},{-1.4678996,-0.76023096,0.07471059,-1.9805152,-3.57395,-1.5714785,-0.11595332,0.73082936,0.8885714,0.12969461,-0.39786038,-2.0393984,0.15305416,-0.52209574,0.29064524},{-5.126447,0.20073855,-1.0637772,-0.789545,-1.7560328,-2.236653,-1.2678372,1.299818,0.37578532,-0.38223448,-1.4709127,-0.20025836,-1.7403144,0.22329466,0.13567343},{-1.3539009,1.0367942,0.056656815,0.25031087,-0.9221405,-3.0342548,-1.4205846,-0.658047,0.57676435,0.85732216,0.0480695,0.17506467,1.8366789,-0.8187,0.72230065},{0.44888708,0.7508996,-0.36977956,0.6591943,-1.5912058,-0.7512161,0.15411693,0.027339926,2.0938654,0.06407733,0.81922835,-2.7856407,1.0016236,-0.018021548,-3.1707122},{-0.1373444,-1.1472272,1.1491569,-2.9887528,-0.48973125,-0.3249079,0.37593246,-0.28837776,-0.38094756,-0.4525293,0.42777443,-0.8930566,-0.3675878,0.5152689,-0.83361363},{-0.09166936,-0.3952395,0.20693,-1.8970567,-1.5605162,-6.366137,1.5254841,0.5501331,-0.16273381,-0.3893933,-1.3396326,-0.25951812,0.71686065,1.0959872,-1.1404152},{0.46000782,0.5985915,-3.136776,-0.42351303,-0.9854742,-0.5012624,0.1930837,1.2315228,-0.7948982,0.3425028,1.0071377,-1.0672256,-0.41401872,-0.8584454,-0.8269052},{-0.7534847,-0.8350659,-0.20468307,-1.1231952,-0.09357993,-4.466729,-0.21883218,0.52087307,-0.35922387,-0.2812182,-1.0855436,0.9763729,-0.24242778,0.07158532,-1.1666652},{-2.2490554,2.5317273,0.42707738,-1.2309791,0.42028618,0.7379528,-0.13171612,-0.49739343,0.8432329,-2.4621732,-1.695073,-0.5498479,0.8249859,0.7264041,0.04547645},{-0.6294846,-0.23291552,0.012744631,-0.10661146,0.8242576,-1.8668159,-0.8568488,0.9232724,2.6430361,0.3123291,-0.42546654,-1.1049993,-0.36012608,-0.086353354,-1.9813442},{-1.98396,1.5164084,0.5749643,-0.95762926,0.07907442,-0.046198312,-0.25638345,-3.1732714,-0.2154949,-0.7922591,0.95067275,-0.48203865,0.8838924,-2.295436,-0.46969247},{-0.7079521,0.87045115,-0.4006155,2.4575074,0.9700958,2.0296347,-0.86397517,0.3597229,0.26120326,-0.43924838,-1.0980662,0.113836065,-0.16872302,0.26439387,1.1899989}},{{-1.8102583,-0.5007188,-0.47685453,2.3591447,0.6830762,0.7667561,0.6978482,-0.8747835,-0.5365629,-1.6912501,-1.2343509,-0.763273,0.99176663,-0.7709801,0.658233},{-0.004081378,0.0070776804,0.030523224,-0.033269513,-0.06429,-0.018058803,-0.017941471,-0.016375167,-0.004248027,-0.080626115,-0.0075687114,-0.08732296,-0.011792551,0.033196833,0.021476272},{-0.45704892,0.67774796,0.603757,0.49117488,0.76780844,0.28470555,-4.6661777,-0.58672506,0.19230622,-0.178425,-0.9027161,-0.8698535,-0.6102393,0.60135216,0.31756386},{0.39437905,0.15793735,-0.053950198,0.8157087,-0.6406571,-0.536095,0.08076323,-0.75191015,-0.15565538,0.1763118,0.39061382,0.3233467,-1.3186783,0.537743,-0.68011576},{-0.12613183,-0.1378085,0.507931,-1.0289223,0.120632745,0.11989516,-0.40216294,0.567874,-0.11920467,0.75920486,0.08917286,-1.9129938,0.99231184,-0.87512934,-0.019605832},{-0.018793374,-0.023820143,-0.01113832,-0.026662804,0.0041853823,0.00574599,-0.008804912,0.009317112,-0.00056927034,0.017054271,-0.0075551267,0.013403232,-0.014119691,-0.019504769,-0.00475443},{0.12513517,0.47757852,-0.27733052,2.3442101,2.0714512,-0.15569206,-0.29843837,1.6450868,0.82974434,2.5880826,-1.906791,-0.2147786,-0.115926005,-0.1695301,1.8590952},{-0.18849188,1.273457,0.19002137,2.0938518,-0.2471807,0.55009836,-0.38194814,-1.5067527,0.29895535,-0.7378302,-0.9398059,0.071771465,-1.0701541,-1.9770373,-0.42865512},{-0.39902338,-0.0274325,-0.12514284,1.0774658,-0.359436,0.22158606,-0.35741362,0.18599324,-3.018676,-0.4436272,-0.5290158,-0.15023491,0.5577761,0.002330727,0.010176455},{0.34286472,-0.5408266,-0.6341331,2.5440466,0.6302684,-0.6817708,0.3353886,-0.5457501,-0.23938672,1.0310062,0.45105684,0.92630166,-0.47387424,0.68837065,0.6379456},{-0.0050570997,-0.0015826443,-0.015210007,-0.0096819615,-0.036401037,-0.123081736,-0.020466449,-0.035627212,-0.025608769,-0.10775715,0.0039716596,-0.084378175,-0.022985205,0.015612138,0.044985216},{-0.4363696,1.4049004,0.12566762,0.87624997,1.8037888,0.8250092,0.40377694,-0.9245073,-0.22581016,-1.4724519,-0.2502898,-0.43248332,0.020654729,0.42017514,0.6250212},{-0.87890416,0.004053087,-0.26020765,1.0866386,-0.662142,0.9494328,-0.06744238,0.76396126,-0.50400925,0.58831215,0.33310017,0.5654597,-0.18370043,0.23043948,-0.5702779},{0.0005861281,0.03256004,0.005429023,0.014723943,-0.00059603574,-0.0019722164,-0.0063103153,0.0077807438,0.017743235,-0.02576942,-0.011634429,-0.009201279,-0.0055672657,-0.0056809094,-0.009956817},{-0.9563951,-0.04814392,-0.68816227,0.47864583,-0.33142468,0.5945873,0.96917164,1.0229287,-0.94137526,-0.4475056,0.77477914,0.92329943,0.46805993,0.50990945,0.34212872}},{{0.0863959,0.0011305679,-0.05944599,0.06493564,0.048935115,0.0011505032,-0.74539167,-0.081110105,0.06767518,-0.050656576,0.0040978235,0.06734765,0.38973442,0.0006220964,-0.10635697}}},
  bias{{1.2453454,-2.0702035,0.49883798,-3.3272011,-2.9324286,-4.177061,1.3651733,0.14565368,-1.6724834,1.8979305,-1.1791564,1.5389514,0.034949772,-1.9741416,-3.1902003},{-0.94044334,-1.1134977,-0.5074645,-1.671513,-0.9766662,0.14515738,-1.9226265,-2.2807405,-2.124047,-1.3478805,1.8199893,0.4011845,-0.3349773,0.73047274,-2.8583248},{-1.766123,-0.0295407,-0.33799306,-0.09637983,-3.547398,0.021739446,-4.0718093,0.0315726,0.5323778,-2.581693,-0.02348713,1.9359396,-3.961898,0.00047175534,-2.9622943},{-0.5961956}} {}

float rw_mmp_r3::evaluate(std::vector<float> input) const {
  std::vector<float> layer_input = scale(input);
  for (unsigned ilayer = 0; ilayer < n_layer; ilayer++) {
    std::vector<float> layer_output;
    layer_output.resize(n_unit[ilayer]);
    for (unsigned iunit = 0; iunit < n_unit[ilayer]; iunit++) {
      float unit_input = dot_product(layer_input,weight[ilayer][iunit])+bias[ilayer][iunit];
      if (activation_type[ilayer]==rw_mmp_r3::ActivationType::relu)
        layer_output[iunit] = relu(unit_input);
      else if (activation_type[ilayer]==rw_mmp_r3::ActivationType::sigmoid)
        layer_output[iunit] = sigmoid(unit_input);
      else if (activation_type[ilayer]==rw_mmp_r3::ActivationType::elu)
        layer_output[iunit] = elu(unit_input);
    }
    layer_input = layer_output;
  }
  return layer_input[0];
}

float rw_mmp_r3::relu(float x) const {
  if (x < 0) return 0;
  return x;
}

float rw_mmp_r3::elu(float x) const {
  if (x < 0) return (exp(x)-1.0);
  return x;
}

float rw_mmp_r3::sigmoid(float x) const {
  return 1.0/(1.0+exp(-1.0*x));
}

float rw_mmp_r3::dot_product(std::vector<float> x, std::vector<float> y) const {
  float output = 0;
  for (unsigned i = 0; i < x.size(); i++) {
    output += x[i]*y[i];
  }
  return output;
}

std::vector<float> rw_mmp_r3::scale(std::vector<float> input) const {
  std::vector<float> output;
  output.resize(n_input);
  for (unsigned iin = 0; iin < n_input; iin++) {
    output[iin] = (input[iin]-scale_mean[iin])/scale_stdv[iin];
  }
  return output;
}

#endif

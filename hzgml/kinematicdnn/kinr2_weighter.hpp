//this file was auto-generated by convert_dnn_to_cpp.py
#ifndef H_KINR2_WEIGHTER
#define H_KINR2_WEIGHTER

#include <cmath>
#include <vector>

/*!\class kinr2_weighter
 class containing DNN such as one produced by TensorFlow
 */
class kinr2_weighter {
public:
  /*!\brief Standard constrctor for initializing DNN
   */
  kinr2_weighter();

  enum class ActivationType{relu, elu, sigmoid};

  /*!\brief evaluates DNN score at a point input
   */
  float evaluate(std::vector<float> input) const;

private:
  std::vector<float> scale(std::vector<float> input) const;
  float dot_product(std::vector<float> x, std::vector<float> y) const;
  float relu(float x) const;
  float elu(float x) const;
  float sigmoid(float x) const;

  unsigned n_layer;
  unsigned n_input;
  std::vector<float> scale_lamb;
  std::vector<float> scale_mean;
  std::vector<float> scale_stdv;
  std::vector<unsigned> n_unit;
  std::vector<kinr2_weighter::ActivationType> activation_type;
  std::vector<std::vector<std::vector<float>>> weight;
  std::vector<std::vector<float>> bias;
};

kinr2_weighter::kinr2_weighter() :
  n_layer(4),
  n_input(8),
  scale_lamb{},
  scale_mean{0.8105883394243922,1.7265301079960864,0.5296446326643344,40.51224835507831,28.98506964732472,33.08242136741949,20.516888614508044,146.3945204823654},
  scale_stdv{0.1702805024265495,0.9232566734676415,0.7557391367667706,29.924443072726028,13.465470872628174,34.10692479557737,16.72062563835896,73.7373724852241},
  n_unit{15,15,15,1},
  activation_type{ActivationType::elu,ActivationType::elu,ActivationType::elu,ActivationType::sigmoid},
  weight{{{0.23593424,-0.10887895,-0.1182405,0.23286161,0.4014228,0.07366435,-0.1902712,0.026689818},{-0.06504233,-0.083495155,0.5420837,-0.27996787,-0.13445692,0.22013938,0.15567668,-0.26429057},{0.0782508,0.0029188553,-0.99059355,-0.22864713,0.10138064,0.26727226,0.55295944,-0.38989386},{0.008215589,-0.05425203,0.3376601,-0.03194526,0.022639193,-0.14921841,-0.97669005,-0.07326516},{-0.1033853,-0.13821575,-0.7270734,-0.0005435086,-0.042050228,0.39879078,0.5562052,-0.46373105},{0.11241615,0.18888605,-0.6912678,-0.19199812,0.22891364,-0.20059572,0.271619,-0.18307124},{-0.012019251,-0.110494845,0.15292971,0.021317353,-0.43003845,0.29094183,-0.08328129,0.12879387},{0.13317601,-0.3442369,-0.20986155,-0.051217396,-0.45305082,0.32338756,0.18649437,0.33982953},{0.21189892,0.075503305,-0.05398422,-0.38564816,-0.6325053,-0.13581489,0.028113415,0.42362228},{-0.004641797,0.19193637,0.122187465,-0.24978904,0.21435036,0.57056826,-0.028733699,-0.11657251},{-0.005131886,-0.075291164,0.36355397,0.0042381296,0.24664289,-0.75274265,0.048531167,-0.41186434},{0.13950436,-0.03974931,0.6451872,0.37783614,0.36240038,-0.1255792,0.45621943,0.10563554},{0.22726059,0.32180792,0.12196387,0.45477653,0.19413246,-0.0017252145,0.14899728,-0.29507044},{0.1848525,0.1003332,-0.1644365,0.13810383,-0.23438634,0.58824885,-0.8561471,0.1027046},{-0.11191501,-0.075952426,0.3160981,-0.16272575,0.0051698913,-0.2876948,0.019634876,-0.45170626}},{{-0.22233757,-0.19813871,-0.31786966,-0.20527765,-0.48578495,0.02870114,-0.17277215,0.044488665,0.3343169,-0.005544068,0.40254483,-0.48291093,0.3714326,0.067323074,0.42882696},{-0.23556332,-0.32937098,-0.58068115,0.41401032,-0.3841074,-0.1647529,-0.33695957,-0.11199742,-0.23947185,-0.35223424,0.3656976,0.31995618,-0.20389737,0.25965983,0.42349294},{0.19641551,-0.08107351,-0.28131098,0.30671513,0.25490016,0.4473429,-0.12149039,0.10524988,0.07194562,0.3990651,0.17422487,0.39019218,0.087832004,0.22364378,-0.47575802},{-0.1993816,-0.034564547,0.1045327,0.19285055,-0.16457947,0.24380401,-0.1809149,0.023705427,0.1173187,0.20202829,0.09622643,-0.050640102,-0.30924284,0.24398273,0.40565693},{0.16305418,0.14609857,-0.42228928,0.49465066,0.028981348,-0.049250655,0.22929054,-0.25571588,0.3320231,-0.042170007,0.22552586,-0.14478338,-0.026560212,0.31058684,-0.35502735},{-0.33924076,0.35583198,-0.107930444,0.08555268,-0.18957436,-0.1313488,-0.10597522,-0.31063086,0.14109373,0.20268446,0.12521838,0.4012496,-0.3283421,-0.29049137,0.020399144},{-0.2938529,-0.07712296,-0.046795484,0.65660083,0.056070037,-0.19796033,-0.22810993,-0.2987893,0.5054104,0.12109849,-0.41590574,0.44045857,-0.0036236416,0.15600672,-0.24193035},{-0.24721521,0.17087094,0.062193815,-0.4015513,0.075373426,0.10757143,0.19492614,0.21924214,-0.50455785,0.11051221,0.49378031,-0.28396294,0.04727226,-0.5071241,-0.26851147},{-0.6212963,0.34160048,0.0023151892,0.0064632897,0.18844277,-0.074051775,0.2821728,-0.16793792,-0.08013067,0.16924156,-0.2320487,0.51947665,-0.34365323,0.22134463,-0.24261715},{-0.24057928,-0.23472215,0.26712197,-0.018342787,0.33724555,0.1605671,0.13862123,0.17042254,0.2572294,-0.35014397,-0.3221082,0.26098928,-0.48351207,-0.2041261,-0.30324975},{0.030139245,-0.44728583,0.041492335,-0.24647139,-0.4142497,-0.27666786,0.10078723,-0.20165539,0.16650653,0.3539265,-0.24131373,-0.15978172,-0.10842401,0.116440274,-0.33812398},{0.15140165,-0.14012562,0.27274376,0.14281537,0.27407873,-0.28794396,-0.37954408,-0.16886213,0.17761888,-0.5123865,0.26521465,-0.06541037,-0.028305775,-0.2845139,0.2764175},{-0.43888146,0.12206314,-0.3080658,-0.26425537,0.32033238,0.2748763,-0.071232274,-0.05461826,0.44175452,0.2990372,-0.019582119,-0.20805798,0.31783876,0.2851186,0.19318931},{-0.5494987,-0.008663537,0.40153572,0.31729218,0.09619096,-0.06302771,-0.21976838,0.3650069,0.0021731923,-0.081070386,-0.09594915,0.216269,-0.074060366,-0.14604174,0.008980235},{-0.38303876,-0.36584082,-0.33741814,0.09088572,-0.3198424,-0.29437575,0.14299506,0.45540994,0.015789479,0.024057312,-0.2636323,-0.5119521,0.07268661,-0.3485375,-0.202728}},{{0.39579254,-0.3589996,0.26432937,0.24056388,-0.18713105,0.03266299,-0.46318805,0.20907941,-0.15179633,-0.22950646,0.08129327,0.2327228,-0.14671701,-0.14442399,0.4313148},{0.20137005,0.3534221,-0.27302068,0.27256584,-0.3328766,0.12870295,-0.046791572,0.5559852,0.02927026,-0.050712448,-0.32961938,0.48719177,-0.17687853,0.068575114,-0.37770557},{0.3183834,0.18866225,0.18999319,-0.13040367,-0.26364714,-0.11567837,-0.13694769,-0.02569999,0.13831256,0.2719095,-0.13745435,-0.01376837,0.02457296,-0.26089373,0.031954855},{0.54324704,0.42311335,0.24576478,0.13427918,0.4127433,-0.0656756,-0.021011276,0.11590839,0.33707258,-0.41436517,0.119635664,-0.19275258,0.010432864,-0.03248822,0.10173722},{-0.048707448,-0.0008785728,-0.35391366,0.269856,0.20993878,0.28847665,-0.42744642,0.21937096,0.15022208,-0.38531306,0.050940685,0.44128987,0.28855875,0.4065993,-0.44988847},{-0.3422876,0.42184824,0.25038296,-0.19736275,0.07148236,0.39922357,0.4804775,0.18066123,0.414232,0.33368483,-0.32269204,-0.28935045,-0.00922507,0.38399732,0.14504093},{-0.055222716,-0.021693299,0.25267574,-0.022158882,-0.030689148,0.21299322,0.2294597,-0.2251035,-0.065308385,-0.21093652,-0.009724672,0.19768831,0.11309849,0.40555784,-0.3788564},{-0.040959686,-0.04337825,-0.2500076,0.2814823,0.10708585,0.33747914,0.52304083,0.3271003,0.048977323,0.09229348,0.021913297,-0.23379138,-0.22567038,0.42821547,0.3538294},{0.06968781,0.01825646,0.07460682,-0.057769477,0.10413717,-0.09190245,-0.21215896,-0.048133943,0.22803886,-0.14616506,-0.22017784,0.059494816,0.18449229,0.026537742,0.044435218},{-0.53790236,0.42316353,0.0739226,0.30609602,0.03745239,-0.1780819,0.08399473,-0.0112992,0.37164804,0.3341086,-0.20609371,-0.27643776,0.22514352,-0.081425525,0.1811087},{-0.19734213,0.34258905,-0.27321863,-0.20344086,0.34651372,-0.18422218,0.31478354,-0.22363076,0.01663585,-0.40869907,0.26279676,-0.15288362,0.14058402,0.19603048,-0.02398439},{-0.022221565,0.22200163,0.17865075,-0.009686616,0.2610927,-0.046677545,-0.3296724,-0.24647236,-0.11170663,0.43927643,-0.10667516,0.28639746,0.16322699,-0.11919607,0.41753986},{-0.34698877,-0.27538908,-0.046262365,-0.106712885,-0.22900523,0.34358805,-0.15629198,0.1847994,-0.28585348,-0.22205329,0.05715088,-0.36234945,0.34126252,-0.23731512,0.26040646},{0.081013516,0.17767692,0.22969894,0.36447775,-0.05597192,-0.30625635,0.22486523,-0.1426333,-0.078359574,0.0842261,0.23167846,-0.10180714,-0.24989748,0.15537998,0.33408624},{-0.13606818,-0.07093915,-0.07116768,0.1973094,-0.16755474,-0.45184675,0.26821688,-0.43600082,0.23767291,-0.16400675,-0.39472497,0.22667713,0.07604361,0.10777316,0.28529978}},{{0.24066433,-0.18164137,0.0049355407,-0.06892837,-0.079344906,0.124926746,0.025232231,0.049310688,-0.008563172,0.07831129,-0.101001225,-0.10963465,-0.14605108,-0.23544295,-0.00886945}}},
  bias{{0.47854477,-0.10318068,-0.032710474,-0.2462375,-0.025467368,-0.09987324,0.06617618,0.0035278825,-0.13753971,-0.10172746,-0.16924141,-0.26208982,0.35915527,-0.09191968,-0.102532394},{0.037483882,-0.06304188,-0.092948765,-0.302193,-0.017142322,-0.20108986,0.057867795,-0.36122993,-0.20438398,-0.05362434,0.04832919,-0.26639536,-0.047931623,-0.19985478,-0.109705545},{-0.08175917,-0.12788896,-0.072869286,-0.03642013,-0.06479034,-0.13841408,-0.019152584,-0.076756634,-0.067569815,-0.0060932334,-0.09276442,-0.074605726,-0.04088858,-0.039731458,-0.014423207},{0.0070496835}} {}

float kinr2_weighter::evaluate(std::vector<float> input) const {
  std::vector<float> layer_input = scale(input);
  for (unsigned ilayer = 0; ilayer < n_layer; ilayer++) {
    std::vector<float> layer_output;
    layer_output.resize(n_unit[ilayer]);
    for (unsigned iunit = 0; iunit < n_unit[ilayer]; iunit++) {
      float unit_input = dot_product(layer_input,weight[ilayer][iunit])+bias[ilayer][iunit];
      if (activation_type[ilayer]==kinr2_weighter::ActivationType::relu)
        layer_output[iunit] = relu(unit_input);
      else if (activation_type[ilayer]==kinr2_weighter::ActivationType::sigmoid)
        layer_output[iunit] = sigmoid(unit_input);
      else if (activation_type[ilayer]==kinr2_weighter::ActivationType::elu)
        layer_output[iunit] = elu(unit_input);
    }
    layer_input = layer_output;
  }
  return layer_input[0];
}

float kinr2_weighter::relu(float x) const {
  if (x < 0) return 0;
  return x;
}

float kinr2_weighter::elu(float x) const {
  if (x < 0) return (exp(x)-1.0);
  return x;
}

float kinr2_weighter::sigmoid(float x) const {
  return 1.0/(1.0+exp(-1.0*x));
}

float kinr2_weighter::dot_product(std::vector<float> x, std::vector<float> y) const {
  float output = 0;
  for (unsigned i = 0; i < x.size(); i++) {
    output += x[i]*y[i];
  }
  return output;
}

std::vector<float> kinr2_weighter::scale(std::vector<float> input) const {
  std::vector<float> output;
  output.resize(n_input);
  for (unsigned iin = 0; iin < n_input; iin++) {
    output[iin] = (input[iin]-scale_mean[iin])/scale_stdv[iin];
  }
  return output;
}

#endif
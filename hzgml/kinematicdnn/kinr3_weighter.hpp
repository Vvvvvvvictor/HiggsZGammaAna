//this file was auto-generated by convert_dnn_to_cpp.py
#ifndef H_KINR3_WEIGHTER
#define H_KINR3_WEIGHTER

#include <cmath>
#include <vector>

/*!\class kinr3_weighter
 class containing DNN such as one produced by TensorFlow
 */
class kinr3_weighter {
public:
  /*!\brief Standard constrctor for initializing DNN
   */
  kinr3_weighter();

  enum class ActivationType{relu, elu, sigmoid};

  /*!\brief evaluates DNN score at a point input
   */
  float evaluate(std::vector<float> input) const;

private:
  std::vector<float> scale(std::vector<float> input) const;
  float dot_product(std::vector<float> x, std::vector<float> y) const;
  float relu(float x) const;
  float elu(float x) const;
  float sigmoid(float x) const;

  unsigned n_layer;
  unsigned n_input;
  std::vector<float> scale_lamb;
  std::vector<float> scale_mean;
  std::vector<float> scale_stdv;
  std::vector<unsigned> n_unit;
  std::vector<kinr3_weighter::ActivationType> activation_type;
  std::vector<std::vector<std::vector<float>>> weight;
  std::vector<std::vector<float>> bias;
};

kinr3_weighter::kinr3_weighter() :
  n_layer(3),
  n_input(8),
  scale_lamb{},
  scale_mean{0.7791253908892419,1.7400198364229884,0.513993557531246,41.01441948156489,30.10464707567765,34.84716663519643,21.705538044551187,149.5698438088174},
  scale_stdv{0.16286916005411572,0.9236607942970871,0.7420794447299215,31.099983838795918,16.967290716701413,38.58704525553766,20.64761468646522,84.58137604434502},
  n_unit{20,20,1},
  activation_type{ActivationType::elu,ActivationType::elu,ActivationType::sigmoid},
  weight{{{0.12879784,0.3341397,0.051092517,-0.19772488,0.58997756,-0.36947772,0.22245744,-0.012422932},{0.10595753,0.1269774,-0.47053152,0.2755716,-0.06912075,0.079576604,0.2721873,-0.07406219},{0.2561268,0.2765889,0.46875477,0.02861498,-0.2081066,-0.3060144,-0.11172289,0.31582358},{-0.10216746,-0.34113866,-0.14356951,-0.43559343,0.4378934,0.38398504,-0.042750034,-0.22966625},{-0.0146808475,-0.16612242,0.045213245,-0.2809335,0.12862019,0.15867276,0.18034606,0.028952004},{-0.20660044,-0.083903596,0.15209879,-0.09988561,0.10098377,0.12711705,0.16472301,0.006395752},{0.21169874,0.07051775,0.57886946,-0.3282839,0.19767849,-0.07711256,0.4249699,-0.42933932},{0.23030958,0.074321225,-0.20584768,0.2651633,-0.23558399,0.34064895,-0.6745864,-0.11640405},{0.19527493,0.16030093,0.2533184,-0.042051673,0.59343684,0.08325792,-0.14206564,-0.21678957},{0.23373398,-0.033916634,0.2838257,0.25161698,-0.051074695,-0.088909216,0.10707332,0.41338095},{0.19230711,-0.2883927,0.07046848,-0.009432174,0.0077954545,0.45343626,-0.18931207,-0.29960516},{-0.18305737,-0.12945327,-0.09914059,0.025122158,-0.19382748,0.28818783,0.16700616,-0.43842405},{0.18684138,-0.24500415,0.18185636,-0.1368049,-0.38525853,0.026818926,0.4331401,0.10965682},{0.07310246,-0.04144116,-0.09587354,-0.06501908,-0.47226915,0.052118212,-0.036022723,-0.032043595},{0.20877306,0.09380547,0.06278838,-0.1916184,0.3034568,0.3118127,-0.0023670308,-0.17211284},{0.053464007,0.032412127,0.152175,-0.044459123,0.30516028,0.09621757,0.12986585,-0.32091922},{0.11008364,-0.08551197,-0.15936583,-0.085097924,-0.22983964,-0.068274975,0.1440022,-0.120999485},{0.17706496,0.33121598,-0.39993557,-0.26296386,0.19466907,0.344127,0.16664204,-0.32872096},{-0.024311084,-0.013485393,-0.40314448,-0.054555606,0.119832896,0.19021234,0.17140742,-0.18345448},{0.20744893,-0.19214973,0.38613728,0.39286995,-0.1164601,0.21850762,0.5011086,0.37903622}},{{-0.13337968,0.17761399,0.1524977,-0.22936602,-0.06238976,0.24605599,0.36901876,-0.09920827,-0.38734955,0.09289037,0.43536028,0.11208272,-0.15680018,0.3365839,0.28137332,0.33715582,0.20553595,-0.2110989,-0.04267832,-0.07167325},{-0.28614706,0.22715756,0.20098887,0.104285896,-0.11836703,0.39337528,0.021547923,0.15523614,0.21155848,-0.04166163,-0.016419094,0.1849974,-0.106131025,-0.22464663,0.02860773,0.0011992727,0.3640829,0.07911384,-0.13344386,-0.004551995},{0.05008528,0.16849278,0.27327815,-0.02764152,0.14596266,0.33915222,-0.32884935,0.00030251255,-0.013337159,0.013340171,0.20893729,-0.131339,0.081900984,0.119646624,0.24483408,-0.33307382,-0.27850705,0.08846882,0.18227713,-0.10020622},{-0.332025,0.29678437,-0.056210358,0.10854409,-0.13480826,0.17483342,0.24668272,-0.07061134,0.09333631,0.113451906,-0.08516718,-0.07505442,0.023500586,0.09390558,-0.070207976,-0.1351326,-0.24849743,0.35370836,-0.2610624,-0.2001779},{0.2857292,0.23572193,-0.29778022,0.084641844,0.00023922286,-0.2258883,-0.33060864,0.023509618,-0.17265339,0.12376376,-0.16717269,0.17932318,0.09705294,-0.25628105,0.107482396,-0.3551629,-0.09998434,0.14402772,-0.26225358,-0.3229655},{0.28219113,-0.12576602,0.05284753,0.20249738,0.23195978,-0.11984721,-0.040183578,0.21216364,-0.28200364,0.23035124,0.22621982,-0.32720673,-0.22858016,0.14853765,0.13019674,0.16544704,0.21948661,-0.46086767,-0.0688835,-0.050886985},{-0.018571248,-0.06438887,0.29520482,0.02583002,-0.07620111,0.37837493,0.21181472,-0.07549364,-0.008399771,0.1008444,-0.10298216,0.17608272,-0.00987212,0.23796256,0.23868535,-0.026837746,0.2590763,-0.303019,-0.0034131897,-0.014134523},{0.2716222,-0.076090224,-0.054399684,-0.2929848,0.085861325,-0.019704215,0.17702289,-0.25027862,0.25493568,0.09447797,-0.035959598,0.11782229,-0.08679266,-0.20977332,0.15692328,-0.17847829,-0.16276313,0.14086181,0.072603755,0.14077112},{-0.04821849,-0.41528934,-0.34408763,-0.118671335,-0.27865604,0.11450012,-0.4734789,0.19290468,0.34911865,0.2010426,0.33285248,-0.31783748,-0.13254263,-0.15289699,0.19585712,0.09764677,0.19641964,-0.47718498,-0.1496395,-0.19123222},{-0.21824591,0.21604523,-0.031387944,0.062020656,0.057737667,0.26379028,0.1155588,-0.09950322,-0.35229024,0.03357442,0.38826707,-0.35244817,-0.31949416,0.071805865,-0.026079725,-0.19442327,-0.21593927,0.15978856,-0.27075112,-0.25074807},{0.21227866,0.10977526,0.115904704,-0.2996949,-0.26113063,-0.10373401,0.3508425,0.08460929,-0.25049073,-0.20524244,0.060319062,-0.116668485,0.013100553,0.13455036,-0.22042356,-0.17114468,0.022454962,0.17453021,-0.18428755,-0.17921555},{0.04455046,0.12739302,-0.35167417,0.05934027,0.33442926,-0.0049122805,-0.36143392,-0.25034,0.075358614,0.22697079,-0.024702618,-0.115533195,0.094743446,-0.045758445,-0.06463064,0.31449008,0.30008152,0.36133397,-0.08783701,0.30997455},{-0.32719523,-0.13100922,-0.017905256,-0.25919044,0.2722082,0.08670134,-0.05025829,0.1978325,-0.32265678,0.33027238,0.23912959,0.14260124,0.028501611,-0.12595709,-0.21686287,-0.3217942,0.093800806,0.3465847,-0.35225004,-0.23266056},{-0.037559066,-0.31429723,-0.010810337,0.078696445,-0.24402922,-0.03370224,-0.10900857,0.13536248,-0.3376379,-0.338714,-0.24359351,-0.06356928,0.30534104,0.13495943,0.1127961,0.38717803,-0.3430204,0.002161798,0.16470423,0.23808852},{-0.034329113,-0.18322195,0.23934309,0.09279929,-0.012947367,-0.35772696,0.14960772,-0.11601432,-0.15214448,-0.16498105,-0.08819635,0.105588466,-0.02243096,-0.06219898,0.21788736,-0.2844809,0.10665434,-0.044138785,0.14039606,0.14383069},{-0.014141122,0.1131169,-0.034568574,0.09907901,0.15567942,-0.12788434,-0.14600462,-0.27316967,0.3566403,0.32169142,-0.0070287054,0.13015479,0.012763648,-0.07753978,0.29154846,-0.11744236,-0.3828797,-0.2621062,-0.03568569,0.18772596},{-0.27036062,0.28423718,-0.054187793,0.18804732,-0.44015247,-0.26866263,-0.1150038,-0.11829247,0.34665322,-0.23371895,0.39611816,-0.033810522,0.2232489,-0.2125244,-0.24603854,0.018849202,0.35491568,0.21851762,-0.16642597,-0.31238273},{0.095772535,-0.21643785,0.29092297,0.20409715,-0.023460565,0.013359198,0.3701355,-0.026674317,-0.22012176,-0.23290963,-0.07446719,0.19605564,-0.13425964,-0.14656475,-0.043732554,0.31346422,0.23177826,-0.39447838,0.07333279,-0.3217615},{-0.08602566,-0.38374215,0.099956155,0.09905532,-0.02296055,0.27554885,-0.33052266,0.35999098,-0.2778012,-0.08644757,0.0093333395,-0.18561898,-0.4404135,0.11661221,0.15748581,0.16439646,-0.19865662,-0.2108817,-0.2901769,-0.004349591},{0.22031653,0.39269695,-0.18957154,-0.0014695772,0.026893351,0.22996438,-0.015375287,0.2755553,0.31821564,0.15522802,-0.14590368,-0.29814297,-0.14209151,0.33335584,-0.27674913,0.31910038,0.33377957,-0.33553874,0.1885303,-0.2722327}},{{0.105408646,-0.004155374,-0.0018270023,-0.2973185,0.18103442,-0.14554936,0.26664498,0.15083924,-0.14583898,0.11895534,-0.14597268,-0.027666437,0.16005497,0.27718323,-0.04456513,0.067456685,0.16288307,-0.24139662,-0.27269867,0.3042301}}},
  bias{{-0.12743905,0.02504444,-0.030286644,-0.13921258,0.10109824,-0.19836017,-0.027927352,-0.17988217,-0.041793946,-0.06720846,0.043502927,-0.06950267,0.0031720053,-0.10770084,-0.06060329,-0.038193002,-0.09875441,-0.054834533,0.021988282,-0.007996031},{0.0017448793,0.022488862,0.007653642,-0.009300974,-0.054574385,0.010727299,-0.032184567,-0.04328796,-0.046760544,-0.026014289,-0.033407915,-0.009511935,-0.06188962,-0.044285182,0.005679035,-0.046235524,-0.05005919,-0.022301294,-0.022521896,-0.04973412},{-0.022025697}} {}

float kinr3_weighter::evaluate(std::vector<float> input) const {
  std::vector<float> layer_input = scale(input);
  for (unsigned ilayer = 0; ilayer < n_layer; ilayer++) {
    std::vector<float> layer_output;
    layer_output.resize(n_unit[ilayer]);
    for (unsigned iunit = 0; iunit < n_unit[ilayer]; iunit++) {
      float unit_input = dot_product(layer_input,weight[ilayer][iunit])+bias[ilayer][iunit];
      if (activation_type[ilayer]==kinr3_weighter::ActivationType::relu)
        layer_output[iunit] = relu(unit_input);
      else if (activation_type[ilayer]==kinr3_weighter::ActivationType::sigmoid)
        layer_output[iunit] = sigmoid(unit_input);
      else if (activation_type[ilayer]==kinr3_weighter::ActivationType::elu)
        layer_output[iunit] = elu(unit_input);
    }
    layer_input = layer_output;
  }
  return layer_input[0];
}

float kinr3_weighter::relu(float x) const {
  if (x < 0) return 0;
  return x;
}

float kinr3_weighter::elu(float x) const {
  if (x < 0) return (exp(x)-1.0);
  return x;
}

float kinr3_weighter::sigmoid(float x) const {
  return 1.0/(1.0+exp(-1.0*x));
}

float kinr3_weighter::dot_product(std::vector<float> x, std::vector<float> y) const {
  float output = 0;
  for (unsigned i = 0; i < x.size(); i++) {
    output += x[i]*y[i];
  }
  return output;
}

std::vector<float> kinr3_weighter::scale(std::vector<float> input) const {
  std::vector<float> output;
  output.resize(n_input);
  for (unsigned iin = 0; iin < n_input; iin++) {
    output[iin] = (input[iin]-scale_mean[iin])/scale_stdv[iin];
  }
  return output;
}

#endif